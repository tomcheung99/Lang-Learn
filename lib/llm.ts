'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
// å»¶é²è¼‰å…¥ WebLLM â€” é¿å…åœ¨æ‰‹æ©Ÿä¸Š import å·¨å¤§çš„ WASM æ¨¡çµ„å°è‡´è¨˜æ†¶é«”çˆ†æ»¿
// åªæœ‰åœ¨çœŸæ­£éœ€è¦æ™‚æ‰ dynamic import
let webllmModule: typeof import('@mlc-ai/web-llm') | null = null;
async function getWebLLM() {
  if (!webllmModule) {
    webllmModule = await import('@mlc-ai/web-llm');
  }
  return webllmModule;
}

// ===== è£ç½®èƒ½åŠ›æª¢æ¸¬ =====
export function isMobile(): boolean {
  if (typeof window === 'undefined') return false;
  // æª¢æ¸¬ UA å’Œè¢å¹•å°ºå¯¸
  const ua = navigator.userAgent.toLowerCase();
  const mobileKeywords = ['mobile', 'android', 'iphone', 'ipad', 'ipod', 'blackberry', 'windows phone'];
  const isMobileUA = mobileKeywords.some(keyword => ua.includes(keyword));
  const isSmallScreen = window.innerWidth <= 768;
  return isMobileUA || isSmallScreen;
}

export function hasWebGPU(): boolean {
  if (typeof navigator === 'undefined') return false;
  return 'gpu' in navigator;
}

export function getDeviceMemoryGB(): number | null {
  if (typeof navigator === 'undefined') return null;
  // @ts-ignore - deviceMemory is experimental
  return navigator.deviceMemory || null;
}

export async function hasEnoughStorage(minBytes: number): Promise<boolean> {
  if (typeof navigator === 'undefined' || !navigator.storage?.estimate) return true; // ç„¡æ³•æª¢æ¸¬å°±å‡è¨­å¤ ç”¨
  try {
    const estimate = await navigator.storage.estimate();
    const available = (estimate.quota || 0) - (estimate.usage || 0);
    return available >= minBytes;
  } catch {
    return true; // æª¢æ¸¬å¤±æ•—å°±å‡è¨­å¤ ç”¨
  }
}

export function shouldUseCloud(): boolean {
  const mobile = isMobile();
  const hasGPU = hasWebGPU();
  const memory = getDeviceMemoryGB();
  
  // æ‰‹æ©Ÿæˆ–æ²’æœ‰ WebGPU â†’ å»ºè­°ç”¨é›²ç«¯
  if (mobile || !hasGPU) return true;
  
  // è¨˜æ†¶é«”å°æ–¼ 4GB â†’ å»ºè­°ç”¨é›²ç«¯
  if (memory !== null && memory < 4) return true;
  
  return false;
}

// é¡å‹å®šç¾©
export interface Sentence {
  original: string;
  translation: string;
  context: string;
}

export interface WordResult {
  word: string;
  meaning: string;
  sentences: Sentence[];
}

export interface LoadingProgress {
  text: string;
  progress: number;
}

export interface ModelConfig {
  id: string;
  name: string;
  description: string;
  size: string;
  modelId: string;
  isThinking?: boolean; // æ˜¯å¦ç‚ºæ¨ç†/æ€è€ƒæ¨¡å‹ï¼ˆQwen3ã€Reasoning ç­‰ï¼‰
}

// æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨
// model_id å¿…é ˆç²¾ç¢ºåŒ¹é… webllm.prebuiltAppConfig.model_list ä¸­çš„ model_id
export const availableModels: ModelConfig[] = [
  {
    id: 'qwen3-1.7b',
    name: 'Qwen3 1.7B',
    description: 'é€Ÿåº¦å¿«ï¼Œä¸­æ—¥è‹±è¡¨ç¾ç©©å®š',
    size: '~1.3GB',
    modelId: 'Qwen3-1.7B-q4f16_1-MLC',
    isThinking: true,
  },
  {
    id: 'qwen3-4b',
    name: 'Qwen3 4B',
    description: 'è³ªé‡æœ€ä½³ï¼Œæ¨è–¦ä½¿ç”¨',
    size: '~2.2GB',
    modelId: 'Qwen3-4B-q4f16_1-MLC',
    isThinking: true,
  },
];

// ===== å¾Œç«¯æ¨¡å¼ =====
export type BackendMode = 'webllm' | 'openrouter';

// OpenRouter æ¨¡å‹é…ç½®
export interface OpenRouterModelConfig {
  id: string;
  name: string;
  description: string;
  modelId: string;
  pricing: string;
}

export const openRouterModels: OpenRouterModelConfig[] = [
  // {
  //   id: 'qwen3-4b',
  //   name: 'Qwen3 4B',
  //   description: 'å°å·§é«˜æ•ˆï¼Œé©åˆå¿«é€Ÿç”Ÿæˆ',
  //   modelId: 'qwen/qwen3-4b',
  //   pricing: '$0.02/M',
  // },
  {
    id: 'qwen3-8b',
    name: 'Qwen3 8B',
    description: 'æ€§èƒ½å‡è¡¡ï¼Œæ¨è–¦ä½¿ç”¨',
    modelId: 'qwen/qwen3-8b',
    pricing: '$0.06/M',
  },
  {
    id: 'qwen3-32b',
    name: 'Qwen3 32B',
    description: 'è³ªé‡æœ€ä½³ï¼Œè¤‡é›œä»»å‹™é¦–é¸',
    modelId: 'qwen/qwen3-32b',
    pricing: '$0.24/M',
  },
  {
    id: 'gpt-oss-20b',
    name: 'GPT OSS 20B',
    description: 'é–‹æºæ¨ç†æ¨¡å‹ï¼Œé‚è¼¯èƒ½åŠ›å¼·',
    modelId: 'openai/gpt-oss-20b',
    pricing: '$0.14/M',
  }
];

// èªè¨€é…ç½®
// systemPrompt ç°¡çŸ­æŒ‡ä»¤ï¼ŒfewShot æä¾›å¤§é‡å¤šè¼ªç¯„ä¾‹è®“å°æ¨¡å‹ç©©å®šè¼¸å‡º
export interface LangConfig {
  placeholder: string;
  icon: string;
  voice: string;
  name: string;
  systemPrompt: string;
  fewShot: Array<{ role: 'user' | 'assistant'; content: string }>;
}

export const langConfigs: Record<string, LangConfig> = {
  ja: { 
    placeholder: 'è¼¸å…¥æ—¥æ–‡...', 
    icon: 'ğŸ‡¯ğŸ‡µ', 
    voice: 'ja-JP', 
    name: 'æ—¥æœ¬èª',
    systemPrompt: 'ä½ æ˜¯æ—¥èªé€ å¥åŠ©æ‰‹ã€‚ç”¨æˆ¶çµ¦ä½ ä¸€å€‹å–®å­—å’Œèªå¢ƒï¼Œä½ ç”¨é€™å€‹å–®å­—é€ ä¸€å€‹å®Œæ•´è‡ªç„¶çš„æ—¥æ–‡å¥å­ï¼Œä¸¦é™„ä¸­æ–‡ç¿»è­¯ã€‚åªè¼¸å‡ºä¸€è¡Œï¼Œæ ¼å¼ï¼šæ—¥æ–‡å¥å­|ä¸­æ–‡ç¿»è­¯ã€‚ä¸è¦è¼¸å‡ºä»»ä½•å…¶ä»–å…§å®¹ã€‚',
    fewShot: [
      { role: 'user', content: 'å–®å­—ï¼šã€Œé£Ÿã¹ã‚‹ã€\nèªå¢ƒï¼šæ—¥å¸¸å°è©±çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œé£Ÿã¹ã‚‹ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'æ¯æœãƒ‘ãƒ³ã‚’é£Ÿã¹ã‚‹ã®ãŒç§ã®ç¿’æ…£ã§ã™|æ¯å¤©æ—©ä¸ŠåƒéºµåŒ…æ˜¯æˆ‘çš„ç¿’æ…£' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œå‹‰å¼·ã€\nèªå¢ƒï¼šå·¥ä½œå ´æ™¯çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œå‹‰å¼·ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å‹‰å¼·ã—ã¦ã€ä»•äº‹ã«æ´»ã‹ã—ãŸã„|æˆ‘æƒ³å­¸ç¿’æ–°çš„ç¨‹å¼èªè¨€ï¼Œæ‡‰ç”¨åœ¨å·¥ä½œä¸Š' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œå¬‰ã—ã„ã€\nèªå¢ƒï¼šæƒ…æ„Ÿè¡¨é”çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œå¬‰ã—ã„ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'å‹é”ã‹ã‚‰ã®æ‰‹ç´™ã‚’èª­ã‚“ã§ã€ã¨ã¦ã‚‚å¬‰ã—ã„æ°—æŒã¡ã«ãªã‚Šã¾ã—ãŸ|è®€äº†æœ‹å‹çš„ä¾†ä¿¡ï¼Œå¿ƒæƒ…è®Šå¾—éå¸¸é–‹å¿ƒ' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œæ¡œã€\nèªå¢ƒï¼šæè¿°äº‹ç‰©çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œæ¡œã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'æ˜¥ã«ãªã‚‹ã¨å…¬åœ’ã®æ¡œãŒç¾ã—ãå’²ãèª‡ã‚Šã¾ã™|åˆ°äº†æ˜¥å¤©ï¼Œå…¬åœ’çš„æ«»èŠ±ç››é–‹å¾—éå¸¸ç¾éº—' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œè¡Œãã€\nèªå¢ƒï¼šæ—…è¡Œå‡ºéŠçš„ä¾‹å¥\n\nè«‹ç”¨ã€Œè¡Œãã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'æ¥æœˆã€å®¶æ—ã¨ä¸€ç·’ã«äº¬éƒ½ã¸æ—…è¡Œã«è¡Œãäºˆå®šã§ã™|ä¸‹å€‹æœˆï¼Œæˆ‘æ‰“ç®—å’Œå®¶äººä¸€èµ·å»äº¬éƒ½æ—…è¡Œ' },
    ]
  },
  en: { 
    placeholder: 'Type English...', 
    icon: 'ğŸ‡¬ğŸ‡§', 
    voice: 'en-US', 
    name: 'English',
    systemPrompt: 'You are a sentence-making assistant. The user gives you a word and a context. You make one complete natural English sentence using that word, with Chinese translation. Output exactly one line in this format: English sentence|ä¸­æ–‡ç¿»è­¯. No other text.',
    fewShot: [
      { role: 'user', content: 'å–®å­—ï¼šã€Œhappyã€\nèªå¢ƒï¼šæ—¥å¸¸å°è©±çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œhappyã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'I feel so happy when I spend time with my family|å’Œå®¶äººåœ¨ä¸€èµ·çš„æ™‚å€™æˆ‘æ„Ÿåˆ°éå¸¸é–‹å¿ƒ' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œimportantã€\nèªå¢ƒï¼šå·¥ä½œå ´æ™¯çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œimportantã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'It is important to meet the deadline for this project|æŒ‰æ™‚å®Œæˆé€™å€‹å°ˆæ¡ˆçš„æˆªæ­¢æ—¥æœŸéå¸¸é‡è¦' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œbeautifulã€\nèªå¢ƒï¼šæè¿°äº‹ç‰©çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œbeautifulã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'The sunset over the ocean was absolutely beautiful|æµ·ä¸Šçš„æ—¥è½çœŸæ˜¯ç¾æ¥µäº†' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œhelpã€\nèªå¢ƒï¼šè«‹æ±‚å¹«åŠ©çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œhelpã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'Could you please help me carry these heavy boxes upstairs|ä½ èƒ½å¹«æˆ‘æŠŠé€™äº›é‡ç®±å­æ¬åˆ°æ¨“ä¸Šå—' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œtravelã€\nèªå¢ƒï¼šæ—…è¡Œå‡ºéŠçš„ä¾‹å¥\n\nè«‹ç”¨ã€Œtravelã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'I love to travel to different countries and experience new cultures|æˆ‘å–œæ­¡å»ä¸åŒçš„åœ‹å®¶æ—…è¡Œï¼Œé«”é©—æ–°çš„æ–‡åŒ–' },
    ]
  },
  zh: { 
    placeholder: 'è¼¸å…¥ä¸­æ–‡...', 
    icon: 'ğŸ‡¹ğŸ‡¼', 
    voice: 'zh-TW', 
    name: 'ä¸­æ–‡',
    systemPrompt: 'ä½ æ˜¯ä¸­æ–‡é€ å¥åŠ©æ‰‹ã€‚ç”¨æˆ¶çµ¦ä½ ä¸€å€‹å–®å­—å’Œèªå¢ƒï¼Œä½ ç”¨é€™å€‹å–®å­—é€ ä¸€å€‹å®Œæ•´è‡ªç„¶çš„ä¸­æ–‡å¥å­ï¼Œä¸¦é™„è‹±æ–‡ç¿»è­¯ã€‚åªè¼¸å‡ºä¸€è¡Œï¼Œæ ¼å¼ï¼šä¸­æ–‡å¥å­|English translationã€‚ä¸è¦è¼¸å‡ºä»»ä½•å…¶ä»–å…§å®¹ã€‚',
    fewShot: [
      { role: 'user', content: 'å–®å­—ï¼šã€Œé–‹å¿ƒã€\nèªå¢ƒï¼šæ—¥å¸¸å°è©±çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œé–‹å¿ƒã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'ä»Šå¤©å’Œæœ‹å‹ä¸€èµ·å»é€›è¡—ï¼Œæˆ‘è¦ºå¾—éå¸¸é–‹å¿ƒ|I went shopping with my friends today and felt very happy' },
      { role: 'user', content: 'å–®å­—ï¼šã€ŒåŠªåŠ›ã€\nèªå¢ƒï¼šå·¥ä½œå ´æ™¯çš„ä¾‹å¥\n\nè«‹ç”¨ã€ŒåŠªåŠ›ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'ä»–æ¯å¤©éƒ½å¾ˆåŠªåŠ›åœ°å·¥ä½œï¼Œå¸Œæœ›èƒ½å¾—åˆ°å‡è·çš„æ©Ÿæœƒ|He works very hard every day, hoping to get a promotion' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œæ€å¿µã€\nèªå¢ƒï¼šæƒ…æ„Ÿè¡¨é”çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œæ€å¿µã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'é›¢é–‹å®¶é„‰ä¹‹å¾Œï¼Œæˆ‘å¸¸å¸¸æ€å¿µé æ–¹çš„çˆ¶æ¯|After leaving my hometown, I often miss my parents far away' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œç¾å‘³ã€\nèªå¢ƒï¼šç¾é£Ÿæ–™ç†çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œç¾å‘³ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'åª½åª½åšçš„ç´…ç‡’è‚‰çœŸçš„éå¸¸ç¾å‘³ï¼Œè®“äººå›å‘³ç„¡çª®|The braised pork my mom makes is really delicious and unforgettable' },
      { role: 'user', content: 'å–®å­—ï¼šã€Œå­¸ç¿’ã€\nèªå¢ƒï¼šå­¸è¡“æ­£å¼çš„ä¾‹å¥\n\nè«‹ç”¨ã€Œå­¸ç¿’ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯' },
      { role: 'assistant', content: 'æŒçºŒå­¸ç¿’æ–°çŸ¥è­˜æ˜¯æå‡å€‹äººç«¶çˆ­åŠ›çš„é—œéµ|Continuously learning new knowledge is the key to improving personal competitiveness' },
    ]
  },
};

// èªå¢ƒé…ç½®ï¼ˆå°å‡ºä¾› UI ä½¿ç”¨ï¼‰
export interface ContextConfig {
  id: string;
  name: string;
  desc: string;
  prompt: string;
  icon: string;
}

export const allContexts: ContextConfig[] = [
  { id: 'daily', name: 'æ—¥å¸¸å°è©±', desc: 'daily conversation', prompt: 'æ—¥å¸¸å°è©±çš„ä¾‹å¥', icon: 'ğŸ’¬' },
  { id: 'work', name: 'å·¥ä½œå ´æ™¯', desc: 'work situation', prompt: 'å·¥ä½œå ´æ™¯çš„ä¾‹å¥', icon: 'ğŸ’¼' },
  { id: 'emotion', name: 'æƒ…æ„Ÿè¡¨é”', desc: 'emotional expression', prompt: 'æƒ…æ„Ÿè¡¨é”çš„ä¾‹å¥', icon: 'â¤ï¸' },
  { id: 'describe', name: 'æè¿°äº‹ç‰©', desc: 'describing something', prompt: 'æè¿°äº‹ç‰©çš„ä¾‹å¥', icon: 'ğŸ”' },
  { id: 'help', name: 'è«‹æ±‚å¹«åŠ©', desc: 'asking for help', prompt: 'è«‹æ±‚å¹«åŠ©çš„ä¾‹å¥', icon: 'ğŸ™' },
  { id: 'travel', name: 'æ—…è¡Œå‡ºéŠ', desc: 'travel and tourism', prompt: 'æ—…è¡Œå‡ºéŠçš„ä¾‹å¥', icon: 'âœˆï¸' },
  { id: 'food', name: 'ç¾é£Ÿæ–™ç†', desc: 'food and cooking', prompt: 'ç¾é£Ÿæ–™ç†çš„ä¾‹å¥', icon: 'ğŸœ' },
  { id: 'literature', name: 'æ–‡å­¸æ›¸é¢', desc: 'literary expression', prompt: 'æ–‡å­¸æ›¸é¢èªçš„ä¾‹å¥', icon: 'ğŸ“š' },
  { id: 'casual', name: 'å£èªä¿šèª', desc: 'slang and casual', prompt: 'å£èªæˆ–ä¿šèªçš„ä¾‹å¥', icon: 'ğŸ˜' },
  { id: 'academic', name: 'å­¸è¡“æ­£å¼', desc: 'academic and formal', prompt: 'å­¸è¡“æˆ–æ­£å¼å ´åˆçš„ä¾‹å¥', icon: 'ğŸ“' },
];

// æ¸…é™¤ AI è¼¸å‡ºä¸­çš„ thinking æ¨™ç±¤ï¼ˆQwen3 ç­‰æ¨ç†æ¨¡å‹æœƒè¼¸å‡º <think>...</think>ï¼‰
function stripThinkingTags(text: string): string {
  // ç§»é™¤ <think>...</think> å€å¡Šï¼ˆåŒ…å«æ›è¡Œï¼‰
  let cleaned = text.replace(/<think>[\s\S]*?<\/think>/gi, '');
  // ç§»é™¤æœªé–‰åˆçš„ <think>... å€å¡Š
  cleaned = cleaned.replace(/<think>[\s\S]*/gi, '');
  // ç§»é™¤æ®˜ç•™çš„ </think>
  cleaned = cleaned.replace(/<\/think>/gi, '');
  cleaned = cleaned.trim();
  
  // å¦‚æœæ¸…ç†å¾Œæœ‰å¤šè¡Œï¼Œå˜—è©¦æ‰¾åˆ°åŒ…å« | çš„é‚£è¡Œ
  if (cleaned.includes('\n')) {
    const lines = cleaned.split('\n').map((l: string) => l.trim()).filter((l: string) => l.length > 0);
    const pipeLine = lines.find((l: string) => l.includes('|'));
    if (pipeLine) return pipeLine;
    // æ²’æœ‰ | å°±å–æœ€å¾Œä¸€è¡Œï¼ˆé€šå¸¸æ˜¯ç­”æ¡ˆï¼‰
    return lines[lines.length - 1] || cleaned;
  }
  
  return cleaned;
}

// ç”Ÿæˆå–®æ¢ä¾‹å¥çš„æ ¸å¿ƒé‚è¼¯ï¼ˆæ”¯æŒé‡è©¦ï¼‰
async function generateOneSentence(
  engine: any,
  config: { systemPrompt: string },
  word: string,
  contextName: string,
  contextPrompt: string,
  lang: string,
  isThinking = false,
  attempt = 1
): Promise<Sentence | null> {
  const MAX_ATTEMPTS = 2;
  const sentenceStartTime = performance.now();
  
  // æ§‹å»º few-shot å¤šè¼ªå°è©± messages
  const userContent = `å–®å­—ï¼šã€Œ${word}ã€\nèªå¢ƒï¼š${contextPrompt}\n\nè«‹ç”¨ã€Œ${word}ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯${isThinking ? ' /no_think' : ''}`;
  
  const messages: Array<{ role: string; content: string }> = [
    { role: 'system', content: config.systemPrompt },
    // æ’å…¥ few-shot ç¯„ä¾‹ï¼ˆå¤šè¼ª user/assistant äº¤æ›¿ï¼‰
    ...((config as any).fewShot || []),
    // çœŸæ­£çš„ç”¨æˆ¶è«‹æ±‚
    { role: 'user', content: userContent }
  ];
  
  const response = await engine.chat.completions.create({
    messages,
    temperature: 0.7,
    // æ€è€ƒæ¨¡å‹çµ¦æ›´å¤š token ä½œç‚ºå®‰å…¨ç¶²ï¼ˆå³ä½¿ /no_think å¤±æ•ˆä¹Ÿæœ‰è¶³å¤ ç©ºé–“ï¼‰
    max_tokens: isThinking ? 500 : 200,
  });

  const rawGenerated = (response.choices?.[0]?.message?.content || '').trim();
  const generated = stripThinkingTags(rawGenerated);

  const sentenceTime = ((performance.now() - sentenceStartTime) / 1000).toFixed(1);
  console.log(`[WebLLM]   ğŸ“ [${contextName}] ${sentenceTime}s (attempt ${attempt}) - åŸå§‹: "${rawGenerated.substring(0, 100)}"`);
  if (rawGenerated !== generated) {
    console.log(`[WebLLM]   ğŸ§¹ å·²æ¸…é™¤ thinking æ¨™ç±¤, æ¸…ç†å¾Œ: "${generated.substring(0, 100)}"`);
  }

  let sentence: Sentence | null = null;

  // è§£æ "åŸæ–‡|ç¿»è­¯" æ ¼å¼
  if (generated && generated.includes('|')) {
    const parts = generated.split('|');
    const original = parts[0].trim();
    const translation = parts.slice(1).join('|').trim();
    // é©—è­‰æ˜¯å®Œæ•´å¥å­ï¼ˆä¸åªæ˜¯å–®å­—é‡è¤‡ï¼‰
    if (original && translation && original.length > 4 && original.length < 300 
        && original !== word && original.length > word.length + 2) {
      sentence = { original, translation, context: contextName };
    }
  }

  // å‚™ç”¨æ–¹æ¡ˆï¼šæ²’æœ‰ | ä½†æœ‰è¶³å¤ é•·åº¦çš„å…§å®¹
  if (!sentence && generated && generated.length > 6 && generated.length < 300 
      && generated !== word && generated.length > word.length + 2) {
    console.log(`[WebLLM]   âš ï¸ æœªæŒ‰æ ¼å¼è¼¸å‡ºï¼Œä½¿ç”¨ç¿»è­¯ API`);
    const translation = await translate(generated, lang);
    sentence = { original: generated, translation, context: contextName };
  }

  // å¦‚æœçµæœä¸å®Œæ•´ï¼ˆå¤ªçŸ­æˆ–åªæ˜¯å–®å­—ï¼‰ï¼Œé‡è©¦ä¸€æ¬¡
  if (!sentence && attempt < MAX_ATTEMPTS) {
    console.log(`[WebLLM]   ğŸ”„ è¼¸å‡ºä¸å®Œæ•´ï¼Œé‡è©¦ç¬¬ ${attempt + 1} æ¬¡...`);
    return generateOneSentence(engine, config, word, contextName, contextPrompt, lang, isThinking, attempt + 1);
  }

  return sentence;
}

// WebLLM Hook
// autoLoad: æ˜¯å¦è‡ªå‹•è¼‰å…¥æ¨¡å‹ï¼ˆæ‰‹æ©Ÿä¸Šæ‡‰è¨­ç‚º false é¿å… OOM å´©æ½°ï¼‰
export function useWebLLM(autoLoad = true) {
  const [isReady, setIsReady] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isGenerating, setIsGenerating] = useState(false);
  const [progress, setProgress] = useState<LoadingProgress | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [currentModel, setCurrentModel] = useState<string>('qwen3-1.7b');
  const [loadingModelName, setLoadingModelName] = useState<string | null>(null);
  const chatRef = useRef<any>(null);
  const isClient = typeof window !== 'undefined';

  // åˆå§‹åŒ–æˆ–åˆ‡æ›æ¨¡å‹
  const loadModel = useCallback(async (modelId: string) => {
    if (!isClient) return;
    
    const modelConfig = availableModels.find(m => m.id === modelId);
    if (!modelConfig) return;

    try {
      setIsLoading(true);
      setError(null);
      setLoadingModelName(modelConfig.name);
      
      // æª¢æŸ¥å„²å­˜ç©ºé–“ï¼ˆæ¨¡å‹ç´„éœ€ 1-3GBï¼‰
      const modelSizeBytes = modelConfig.size.includes('1.3GB') ? 1.3e9 : 2.2e9;
      const hasStorage = await hasEnoughStorage(modelSizeBytes * 1.5); // é ç•™ 50% buffer
      if (!hasStorage) {
        throw new Error('å„²å­˜ç©ºé–“ä¸è¶³ï¼Œç„¡æ³•ä¸‹è¼‰æ¨¡å‹ã€‚å»ºè­°ä½¿ç”¨é›²ç«¯ API æ¨¡å¼ã€‚');
      }
      
      // å¦‚æœå·²æœ‰æ¨¡å‹ï¼Œå…ˆå¸è¼‰
      if (chatRef.current) {
        try {
          await chatRef.current.unload();
        } catch (e) {
          console.warn('Error unloading engine:', e);
        }
        chatRef.current = null;
      }
      
      const loadStartTime = performance.now();
      console.log(`[WebLLM] é–‹å§‹è¼‰å…¥æ¨¡å‹: ${modelConfig.name} (${modelConfig.modelId})`);
      
      // å»¶é²è¼‰å…¥ WebLLM æ¨¡çµ„ï¼Œé¿å…æ‰‹æ©Ÿä¸Šä¸å¿…è¦çš„è¨˜æ†¶é«”ä½”ç”¨
      const webllmLib = await getWebLLM();
      
      // ä½¿ç”¨ CreateMLCEngine API
      const engine = await webllmLib.CreateMLCEngine(modelConfig.modelId, {
        initProgressCallback: (report: any) => {
          if (report) {
            setProgress({
              text: report.text || 'è¼‰å…¥ä¸­...',
              progress: typeof report.progress === 'number' ? report.progress : 0,
            });
          }
        },
      });
      
      const loadTime = ((performance.now() - loadStartTime) / 1000).toFixed(1);
      console.log(`[WebLLM] âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ: ${modelConfig.name}ï¼Œè€—æ™‚ ${loadTime}s`);
      
      chatRef.current = engine;
      setCurrentModel(modelId);
      setIsReady(true);
      setError(null);
    } catch (err: any) {
      console.error('WebLLM init failed:', err);
      
      // å‹å–„åŒ–éŒ¯èª¤è¨Šæ¯
      let friendlyError = err.message || 'æ¨¡å‹è¼‰å…¥å¤±æ•—';
      
      if (friendlyError.includes('GPU') || friendlyError.includes('WebGPU')) {
        friendlyError = 'âŒ æ­¤è£ç½®ä¸æ”¯æ´ WebGPUï¼Œè«‹ä½¿ç”¨ã€Œé›²ç«¯ APIã€æ¨¡å¼';
      } else if (friendlyError.includes('å„²å­˜ç©ºé–“')) {
        friendlyError = `âŒ ${friendlyError}`; // å·²ç¶“æ˜¯å‹å–„è¨Šæ¯
      } else if (friendlyError.includes('memory') || friendlyError.toLowerCase().includes('oom')) {
        friendlyError = 'âŒ è¨˜æ†¶é«”ä¸è¶³ï¼Œå»ºè­°ä½¿ç”¨ã€Œé›²ç«¯ APIã€æ¨¡å¼æˆ–é¸æ“‡è¼ƒå°çš„æ¨¡å‹';
      } else if (friendlyError.includes('Cannot find model')) {
        friendlyError = `âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š${modelConfig.name} ä¸å­˜åœ¨`;
      } else {
        friendlyError = `âŒ ${friendlyError}`;
      }
      
      setError(friendlyError);
      setIsReady(false);
    } finally {
      setIsLoading(false);
      setProgress(null);
      setLoadingModelName(null);
    }
  }, [isClient]);

  // å¸è¼‰æ¨¡å‹ï¼ˆé‡‹æ”¾è¨˜æ†¶é«”ï¼Œåˆ‡æ›åˆ°é›²ç«¯æ™‚ä½¿ç”¨ï¼‰
  const unloadModel = useCallback(async () => {
    if (chatRef.current) {
      try {
        await chatRef.current.unload();
        console.log('[WebLLM] ğŸ—‘ï¸ æ¨¡å‹å·²å¸è¼‰ï¼Œé‡‹æ”¾è¨˜æ†¶é«”');
      } catch (e) {
        console.warn('Error unloading engine:', e);
      }
      chatRef.current = null;
    }
    setIsReady(false);
    setError(null);
    setProgress(null);
  }, []);

  // åˆå§‹è¼‰å…¥é»˜èªæ¨¡å‹ï¼ˆåƒ…åœ¨ autoLoad=true ä¸”éæ‰‹æ©Ÿæ™‚ï¼‰
  useEffect(() => {
    if (!autoLoad) {
      console.log('[WebLLM] â­ï¸ è·³éè‡ªå‹•è¼‰å…¥ï¼ˆautoLoad=falseï¼‰');
      return;
    }
    if (shouldUseCloud()) {
      console.log('[WebLLM] â­ï¸ è·³éè‡ªå‹•è¼‰å…¥ï¼ˆåµæ¸¬åˆ°æ‰‹æ©Ÿ/ä½è¨˜æ†¶é«”è£ç½®ï¼‰');
      return;
    }
    loadModel('qwen3-1.7b');
  }, [loadModel, autoLoad]);

  const generateSentences = useCallback(async (
    word: string,
    lang: string,
    selectedContextIds?: string[],
    onSentence?: (sentence: Sentence) => void
  ): Promise<Sentence[]> => {
    if (!chatRef.current || !isReady) return [];

    setIsGenerating(true);
    const totalStartTime = performance.now();
    console.log(`[WebLLM] ğŸ”„ é–‹å§‹ç”Ÿæˆä¾‹å¥: "${word}" (${lang})`);
    
    const sentences: Sentence[] = [];
    const config = langConfigs[lang];
    
    // æ ¹æ“šç”¨æˆ¶é¸æ“‡éæ¿¾èªå¢ƒ
    const selectedContexts = selectedContextIds && selectedContextIds.length > 0
      ? allContexts.filter(c => selectedContextIds.includes(c.id))
      : allContexts.slice(0, 5); // é»˜èªå‰5å€‹

    // æª¢æŸ¥ç•¶å‰æ¨¡å‹æ˜¯å¦ç‚ºæ€è€ƒæ¨¡å‹
    const currentModelConfig = availableModels.find(m => m.id === currentModel);
    const isThinking = currentModelConfig?.isThinking ?? false;
    if (isThinking) {
      console.log(`[WebLLM] ğŸ’­ æ€è€ƒæ¨¡å‹åµæ¸¬åˆ°ï¼Œå·²å•Ÿç”¨ /no_think æ¨¡å¼`);
    }

    for (const { name, prompt } of selectedContexts) {
      try {
        const sentence = await generateOneSentence(chatRef.current, config, word, name, prompt, lang, isThinking);
        if (sentence) {
          sentences.push(sentence);
          if (onSentence) {
            onSentence(sentence);
          }
        }
      } catch (e) {
        console.error('[WebLLM]   âŒ Generation failed:', e);
      }
    }

    const totalTime = ((performance.now() - totalStartTime) / 1000).toFixed(1);
    console.log(`[WebLLM] âœ… ç”Ÿæˆå®Œæˆ: ${sentences.length} å€‹ä¾‹å¥ï¼Œç¸½è€—æ™‚ ${totalTime}s`);
    setIsGenerating(false);
    return sentences;
  }, [isReady, currentModel]);

  // é‡æ–°ç”Ÿæˆå–®æ¢ä¾‹å¥
  const regenerateSingle = useCallback(async (
    word: string,
    lang: string,
    contextId: string
  ): Promise<Sentence | null> => {
    if (!chatRef.current || !isReady) return null;
    
    const ctx = allContexts.find(c => c.id === contextId);
    if (!ctx) return null;
    
    const config = langConfigs[lang];
    const currentModelConfig = availableModels.find(m => m.id === currentModel);
    const isThinking = currentModelConfig?.isThinking ?? false;
    console.log(`[WebLLM] ğŸ”„ é‡æ–°ç”Ÿæˆ: "${word}" [${ctx.name}]${isThinking ? ' (no_think)' : ''}`);
    
    try {
      const sentence = await generateOneSentence(chatRef.current, config, word, ctx.name, ctx.prompt, lang, isThinking);
      return sentence;
    } catch (e) {
      console.error('[WebLLM] âŒ Regenerate failed:', e);
      return null;
    }
  }, [isReady, currentModel]);

  return { 
    isReady, 
    isLoading, 
    isGenerating,
    progress, 
    error, 
    currentModel,
    loadingModelName,
    loadModel,
    unloadModel,
    generateSentences,
    regenerateSingle,
    deviceInfo: {
      isMobile: isMobile(),
      hasWebGPU: hasWebGPU(),
      memoryGB: getDeviceMemoryGB(),
      shouldUseCloud: shouldUseCloud(),
    }
  };
}

// ===== OpenRouter API å¾Œç«¯ =====
// é€é OpenRouter API ç”Ÿæˆå–®æ¢ä¾‹å¥ï¼ˆä¾›æ‰‹æ©Ÿç­‰ä¸æ”¯æ´ WebGPU çš„è£ç½®ä½¿ç”¨ï¼‰
async function generateOneSentenceAPI(
  apiKey: string,
  config: { systemPrompt: string },
  word: string,
  contextName: string,
  contextPrompt: string,
  lang: string,
  modelId: string,
  attempt = 1
): Promise<Sentence | null> {
  const MAX_ATTEMPTS = 2;
  const sentenceStartTime = performance.now();
  
  const userContent = `å–®å­—ï¼šã€Œ${word}ã€\nèªå¢ƒï¼š${contextPrompt}\n\nè«‹ç”¨ã€Œ${word}ã€é€ ä¸€å€‹å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ï¼šå¥å­|ç¿»è­¯ /no_think`;
  
  const messages = [
    { role: 'system', content: config.systemPrompt },
    ...((config as any).fewShot || []),
    { role: 'user', content: userContent }
  ];

  // ä½¿ç”¨ AbortController è¨­å®šè¶…æ™‚ï¼Œé¿å… Safari "a problem repeatedly occurred"
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 30000); // 30ç§’è¶…æ™‚

  try {
    const res = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
        'HTTP-Referer': typeof window !== 'undefined' ? window.location.origin : 'https://lang-learn.vercel.app',
        'X-Title': 'Lang-Learn',
      },
      body: JSON.stringify({
        model: modelId,
        messages,
        temperature: 0.7,
        max_tokens: 500,
      }),
      signal: controller.signal,
    });

    clearTimeout(timeoutId);

    if (!res.ok) {
      const errBody = await res.text().catch(() => 'Unknown error');
      console.error(`[OpenRouter] âŒ HTTP ${res.status}: ${errBody}`);
      if (attempt < MAX_ATTEMPTS) {
        await new Promise(r => setTimeout(r, 500)); // çŸ­æš«å»¶é²é¿å…éå¿«é‡è©¦
        return generateOneSentenceAPI(apiKey, config, word, contextName, contextPrompt, lang, modelId, attempt + 1);
      }
      return null;
    }

    const data = await res.json();
    const rawGenerated = (data.choices?.[0]?.message?.content || '').trim();
    const generated = stripThinkingTags(rawGenerated);

    const sentenceTime = ((performance.now() - sentenceStartTime) / 1000).toFixed(1);
    console.log(`[OpenRouter] ğŸ“ [${contextName}] ${sentenceTime}s (attempt ${attempt}) - "${rawGenerated.substring(0, 100)}"`);

    let sentence: Sentence | null = null;

    if (generated && generated.includes('|')) {
      const parts = generated.split('|');
      const original = parts[0].trim();
      const translation = parts.slice(1).join('|').trim();
      if (original && translation && original.length > 4 && original.length < 300
          && original !== word && original.length > word.length + 2) {
        sentence = { original, translation, context: contextName };
      }
    }

    if (!sentence && generated && generated.length > 6 && generated.length < 300
        && generated !== word && generated.length > word.length + 2) {
      const translation = await translate(generated, lang);
      sentence = { original: generated, translation, context: contextName };
    }

    if (!sentence && attempt < MAX_ATTEMPTS) {
      console.log(`[OpenRouter] ğŸ”„ è¼¸å‡ºä¸å®Œæ•´ï¼Œé‡è©¦ç¬¬ ${attempt + 1} æ¬¡...`);
      await new Promise(r => setTimeout(r, 300));
      return generateOneSentenceAPI(apiKey, config, word, contextName, contextPrompt, lang, modelId, attempt + 1);
    }

    return sentence;
  } catch (e: any) {
    clearTimeout(timeoutId);
    
    // å€åˆ†è¶…æ™‚éŒ¯èª¤å’Œå…¶ä»–éŒ¯èª¤
    if (e.name === 'AbortError') {
      console.error(`[OpenRouter] â±ï¸ è«‹æ±‚è¶…æ™‚: [${contextName}]`);
    } else {
      console.error('[OpenRouter] âŒ Fetch error:', e?.message || e);
    }
    
    if (attempt < MAX_ATTEMPTS) {
      await new Promise(r => setTimeout(r, 500));
      return generateOneSentenceAPI(apiKey, config, word, contextName, contextPrompt, lang, modelId, attempt + 1);
    }
    return null;
  }
}

// OpenRouter Hookï¼ˆAPI æ¨¡å¼ï¼Œæ‰‹æ©Ÿä¹Ÿèƒ½ç”¨ï¼‰
export function useOpenRouter() {
  const [apiKey, setApiKey] = useState<string>('');
  const [isGenerating, setIsGenerating] = useState(false);
  const [currentOpenRouterModel, setCurrentOpenRouterModel] = useState<string>('qwen3-8b');
  const isClient = typeof window !== 'undefined';

  // å„ªå…ˆä½¿ç”¨ç’°å¢ƒè®Šæ•¸çš„ API keyï¼ˆä¼ºæœå™¨ç«¯è¨­å®šï¼‰ï¼Œå¦å‰‡å¾ localStorage è®€å–
  const serverApiKey = typeof process !== 'undefined' ? process.env.NEXT_PUBLIC_OPENROUTER_API_KEY : undefined;
  const effectiveApiKey = serverApiKey || apiKey;
  const hasServerKey = !!serverApiKey;

  useEffect(() => {
    if (!isClient || hasServerKey) return;
    const saved = localStorage.getItem('lang-learn-openrouter-key');
    if (saved) setApiKey(saved);
    const savedModel = localStorage.getItem('lang-learn-openrouter-model');
    if (savedModel) setCurrentOpenRouterModel(savedModel);
  }, [isClient, hasServerKey]);

  const saveApiKey = useCallback((key: string) => {
    if (hasServerKey) return; // ä¼ºæœå™¨ç«¯å·²æœ‰ keyï¼Œä¸éœ€è¦å„²å­˜
    setApiKey(key);
    if (isClient) {
      if (key) {
        localStorage.setItem('lang-learn-openrouter-key', key);
      } else {
        localStorage.removeItem('lang-learn-openrouter-key');
      }
    }
  }, [isClient, hasServerKey]);

  const setOpenRouterModel = useCallback((modelId: string) => {
    setCurrentOpenRouterModel(modelId);
    if (isClient) {
      localStorage.setItem('lang-learn-openrouter-model', modelId);
    }
  }, [isClient]);

  const isReady = !!effectiveApiKey;

  const generateSentences = useCallback(async (
    word: string,
    lang: string,
    selectedContextIds?: string[],
    onSentence?: (sentence: Sentence) => void
  ): Promise<Sentence[]> => {
    if (!effectiveApiKey) return [];

    setIsGenerating(true);
    const totalStartTime = performance.now();
    console.log(`[OpenRouter] ğŸ”„ é–‹å§‹ä¸¦è¡Œç”Ÿæˆä¾‹å¥: "${word}" (${lang})`);

    const config = langConfigs[lang];
    const selectedContexts = selectedContextIds && selectedContextIds.length > 0
      ? allContexts.filter(c => selectedContextIds.includes(c.id))
      : allContexts.slice(0, 5);

    const modelConfig = openRouterModels.find(m => m.id === currentOpenRouterModel);
    const modelIdToUse = modelConfig?.modelId || 'qwen/qwen3-8b';

    // ğŸš€ Batch Mode: ä¸¦è¡Œç™¼é€æ‰€æœ‰ API è«‹æ±‚
    const promises = selectedContexts.map(async ({ name, prompt }) => {
      try {
        const sentence = await generateOneSentenceAPI(effectiveApiKey, config, word, name, prompt, lang, modelIdToUse);
        if (sentence && onSentence) {
          onSentence(sentence); // å³æ™‚å›å‚³æ¯å€‹å®Œæˆçš„çµæœ
        }
        return sentence;
      } catch (e) {
        console.error(`[OpenRouter] âŒ [${name}] ç”Ÿæˆå¤±æ•—:`, e);
        return null;
      }
    });

    const results = await Promise.all(promises);
    const sentences = results.filter((s): s is Sentence => s !== null);

    const totalTime = ((performance.now() - totalStartTime) / 1000).toFixed(1);
    console.log(`[OpenRouter] âœ… ä¸¦è¡Œç”Ÿæˆå®Œæˆ: ${sentences.length}/${selectedContexts.length} å€‹ä¾‹å¥ï¼Œç¸½è€—æ™‚ ${totalTime}s`);
    setIsGenerating(false);
    return sentences;
  }, [effectiveApiKey, currentOpenRouterModel]);

  const regenerateSingle = useCallback(async (
    word: string,
    lang: string,
    contextId: string
  ): Promise<Sentence | null> => {
    if (!effectiveApiKey) return null;
    const ctx = allContexts.find(c => c.id === contextId);
    if (!ctx) return null;
    const config = langConfigs[lang];
    console.log(`[OpenRouter] ğŸ”„ é‡æ–°ç”Ÿæˆ: "${word}" [${ctx.name}]`);
    try {
      const modelConfig = openRouterModels.find(m => m.id === currentOpenRouterModel);
      const modelIdToUse = modelConfig?.modelId || 'qwen/qwen3-8b';
      return await generateOneSentenceAPI(effectiveApiKey, config, word, ctx.name, ctx.prompt, lang, modelIdToUse);
    } catch (e) {
      console.error('[OpenRouter] âŒ Regenerate failed:', e);
      return null;
    }
  }, [effectiveApiKey, currentOpenRouterModel]);

  return {
    isReady,
    isLoading: false,
    isGenerating,
    progress: null as LoadingProgress | null,
    error: effectiveApiKey ? null : 'è«‹è¼¸å…¥ OpenRouter API Key',
    currentModel: currentOpenRouterModel,
    loadingModelName: null as string | null,
    apiKey,
    hasServerKey,
    saveApiKey,
    setOpenRouterModel,
    generateSentences,
    regenerateSingle,
  };
}

// ç¿»è­¯
async function translate(text: string, fromLang: string): Promise<string> {
  try {
    const from = fromLang === 'ja' ? 'ja' : fromLang === 'zh' ? 'zh' : 'en';
    const to = fromLang === 'en' ? 'zh' : 'en';
    
    const response = await fetch(
      `https://api.mymemory.translated.net/get?q=${encodeURIComponent(text)}&langpair=${from}|${to}`
    );
    const data = await response.json();
    return data.responseData?.translatedText || '(ç¿»è­¯å¤±æ•—)';
  } catch {
    return '(ç¿»è­¯å¤±æ•—)';
  }
}

// æ’­æ”¾éŸ³é »
export function playAudio(text: string, lang: string) {
  if (typeof window === 'undefined') return;
  if (!('speechSynthesis' in window)) return;

  window.speechSynthesis.cancel();
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = langConfigs[lang]?.voice || 'en-US';
  utterance.rate = 0.9;
  window.speechSynthesis.speak(utterance);
}

// æ­·å²è¨˜éŒ„
export function useHistory() {
  const [history, setHistory] = useState<Array<{ word: string; lang: string }>>([]);
  const [isClient, setIsClient] = useState(false);

  useEffect(() => {
    setIsClient(true);
    const saved = localStorage.getItem('lang-learn-history');
    if (saved) {
      setHistory(JSON.parse(saved));
    }
  }, []);

  const addToHistory = useCallback((word: string, lang: string) => {
    if (!isClient) return;
    setHistory((prev) => {
      const filtered = prev.filter((h) => !(h.word === word && h.lang === lang));
      const newHistory = [{ word, lang }, ...filtered].slice(0, 20);
      localStorage.setItem('lang-learn-history', JSON.stringify(newHistory));
      return newHistory;
    });
  }, [isClient]);

  const clearHistory = useCallback(() => {
    if (!isClient) return;
    setHistory([]);
    localStorage.removeItem('lang-learn-history');
  }, [isClient]);

  return { history, addToHistory, clearHistory, isClient };
}

// ä¸»é¡Œåˆ‡æ›
export function useTheme() {
  const [theme, setTheme] = useState<'light' | 'dark'>('dark');
  const [mounted, setMounted] = useState(false);

  useEffect(() => {
    setMounted(true);
    const saved = localStorage.getItem('lang-learn-theme') as 'light' | 'dark';
    if (saved) {
      setTheme(saved);
      document.documentElement.setAttribute('data-theme', saved);
    } else {
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      const initialTheme = prefersDark ? 'dark' : 'light';
      setTheme(initialTheme);
      document.documentElement.setAttribute('data-theme', initialTheme);
    }
  }, []);

  const toggleTheme = useCallback(() => {
    const newTheme = theme === 'light' ? 'dark' : 'light';
    setTheme(newTheme);
    document.documentElement.setAttribute('data-theme', newTheme);
    localStorage.setItem('lang-learn-theme', newTheme);
  }, [theme]);

  return { theme, toggleTheme, mounted };
}
