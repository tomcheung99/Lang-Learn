'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import * as webllm from '@mlc-ai/web-llm';

// é¡å‹å®šç¾©
export interface Sentence {
  original: string;
  translation: string;
  context: string;
}

export interface WordResult {
  word: string;
  meaning: string;
  sentences: Sentence[];
}

export interface LoadingProgress {
  text: string;
  progress: number;
}

export interface ModelConfig {
  id: string;
  name: string;
  description: string;
  size: string;
  modelId: string;
}

// æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨
// model_id å¿…é ˆç²¾ç¢ºåŒ¹é… webllm.prebuiltAppConfig.model_list ä¸­çš„ model_id
export const availableModels: ModelConfig[] = [
  {
    id: 'llama-3.2-1b',
    name: 'Llama 3.2 1B',
    description: 'Meta æœ€æ–°ï¼Œé€Ÿåº¦æœ€å¿«',
    size: '~400MB',
    modelId: 'Llama-3.2-1B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'llama-3.2-3b',
    name: 'Llama 3.2 3B',
    description: 'Meta æœ€æ–°ï¼Œè³ªé‡æ›´å¥½',
    size: '~1.2GB',
    modelId: 'Llama-3.2-3B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'qwen-2.5-1.5b',
    name: 'Qwen 2.5 1.5B',
    description: 'é˜¿é‡Œå·´å·´ï¼Œä¸­æ–‡æ¥µå¼·',
    size: '~800MB',
    modelId: 'Qwen2.5-1.5B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'smollm-1.7b',
    name: 'SmolLM 1.7B',
    description: 'Hugging Faceï¼Œæœ€æ–°å°æ¨¡å‹',
    size: '~750MB',
    modelId: 'SmolLM2-1.7B-Instruct-q4f16_1-MLC',
  },
  {
    id: 'phi-3.5',
    name: 'Phi 3.5 Mini',
    description: 'Microsoftï¼Œæ¨ç†èƒ½åŠ›å¼·',
    size: '~900MB',
    modelId: 'Phi-3.5-mini-instruct-q4f16_1-MLC',
  },
];

// èªè¨€é…ç½®
export const langConfigs: Record<string, { placeholder: string; icon: string; voice: string; name: string; systemPrompt: string }> = {
  ja: { 
    placeholder: 'è¼¸å…¥æ—¥æ–‡...', 
    icon: 'ğŸ‡¯ğŸ‡µ', 
    voice: 'ja-JP', 
    name: 'æ—¥æœ¬èª',
    systemPrompt: 'ä½ æ˜¯æ—¥èªæ•™å­¸åŠ©æ‰‹ã€‚è«‹ç”¨ç”¨æˆ¶æä¾›çš„å–®å­—ç”Ÿæˆè‡ªç„¶çš„æ—¥æ–‡ä¾‹å¥ã€‚åªè¼¸å‡ºä¾‹å¥æœ¬èº«ï¼Œä¸éœ€è¦è§£é‡‹ã€‚'
  },
  en: { 
    placeholder: 'Type English...', 
    icon: 'ğŸ‡¬ğŸ‡§', 
    voice: 'en-US', 
    name: 'English',
    systemPrompt: 'You are an English teaching assistant. Generate natural English sentences using the provided word. Output only the sentence, no explanation.'
  },
  zh: { 
    placeholder: 'è¼¸å…¥ä¸­æ–‡...', 
    icon: 'ğŸ‡¹ğŸ‡¼', 
    voice: 'zh-TW', 
    name: 'ä¸­æ–‡',
    systemPrompt: 'ä½ æ˜¯ä¸­æ–‡æ•™å­¸åŠ©æ‰‹ã€‚è«‹ç”¨ç”¨æˆ¶æä¾›çš„å–®å­—ç”Ÿæˆè‡ªç„¶çš„ä¸­æ–‡ä¾‹å¥ã€‚åªè¼¸å‡ºä¾‹å¥æœ¬èº«ï¼Œä¸éœ€è¦è§£é‡‹ã€‚'
  },
};

// èªå¢ƒé…ç½®
const contexts = [
  { name: 'æ—¥å¸¸å°è©±', desc: 'daily conversation', prompt: 'æ—¥å¸¸å°è©±çš„ä¾‹å¥' },
  { name: 'å·¥ä½œå ´æ™¯', desc: 'work situation', prompt: 'å·¥ä½œå ´æ™¯çš„ä¾‹å¥' },
  { name: 'æƒ…æ„Ÿè¡¨é”', desc: 'emotional expression', prompt: 'æƒ…æ„Ÿè¡¨é”çš„ä¾‹å¥' },
  { name: 'æè¿°äº‹ç‰©', desc: 'describing something', prompt: 'æè¿°äº‹ç‰©çš„ä¾‹å¥' },
  { name: 'è«‹æ±‚å¹«åŠ©', desc: 'asking for help', prompt: 'è«‹æ±‚å¹«åŠ©çš„ä¾‹å¥' },
];

// WebLLM Hook
export function useWebLLM() {
  const [isReady, setIsReady] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [progress, setProgress] = useState<LoadingProgress | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [currentModel, setCurrentModel] = useState<string>('llama-3.2-1b');
  const chatRef = useRef<any>(null);
  const isClient = typeof window !== 'undefined';

  // åˆå§‹åŒ–æˆ–åˆ‡æ›æ¨¡å‹
  const loadModel = useCallback(async (modelId: string) => {
    if (!isClient) return;
    
    const modelConfig = availableModels.find(m => m.id === modelId);
    if (!modelConfig) return;

    try {
      setIsLoading(true);
      setError(null);
      
      // å¦‚æœå·²æœ‰æ¨¡å‹ï¼Œå…ˆå¸è¼‰
      if (chatRef.current) {
        try {
          await chatRef.current.unload();
        } catch (e) {
          console.warn('Error unloading engine:', e);
        }
        chatRef.current = null;
      }
      
      // ä½¿ç”¨ CreateMLCEngine API
      const engine = await webllm.CreateMLCEngine(modelConfig.modelId, {
        initProgressCallback: (report: any) => {
          if (report) {
            setProgress({
              text: report.text || 'è¼‰å…¥ä¸­...',
              progress: typeof report.progress === 'number' ? report.progress : 0,
            });
          }
        },
      });
      
      chatRef.current = engine;
      setCurrentModel(modelId);
      setIsReady(true);
      setError(null);
    } catch (err: any) {
      console.error('WebLLM init failed:', err);
      // å¦‚æœæ˜¯æ¨¡å‹ä¸å­˜åœ¨éŒ¯èª¤ï¼Œå˜—è©¦ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„æ¨¡å‹
      if (err.message && err.message.includes('Cannot find model')) {
        setError('æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨ Llama 3.2 1B');
        // éè¿´èª¿ç”¨ï¼Œæ”¹ç”¨å‚™é¸æ¨¡å‹
        if (modelId !== 'llama-3.2-1b') {
          setTimeout(() => loadModel('llama-3.2-1b'), 1000);
        } else {
          setError('æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼šæ²’æœ‰å¯ç”¨çš„å‚™é¸æ¨¡å‹');
          setIsReady(false);
        }
      } else {
        setError(err.message || 'æ¨¡å‹è¼‰å…¥å¤±æ•—');
        setIsReady(false);
      }
    } finally {
      setIsLoading(false);
      setProgress(null);
    }
  }, [isClient]);

  // åˆå§‹è¼‰å…¥é»˜èªæ¨¡å‹
  useEffect(() => {
    loadModel('llama-3.2-1b');
  }, [loadModel]);

  const generateSentences = useCallback(async (
    word: string,
    lang: string
  ): Promise<Sentence[]> => {
    if (!chatRef.current || !isReady) return [];

    const sentences: Sentence[] = [];
    const config = langConfigs[lang];

    for (const { name, prompt } of contexts) {
      try {
        const response = await chatRef.current.chat.completions.create({
          messages: [
            { role: 'system', content: config.systemPrompt },
            { role: 'user', content: `å–®å­—ï¼š"${word}"\nèªå¢ƒï¼š${prompt}\n\nè«‹ç”Ÿæˆä¸€å€‹è‡ªç„¶çš„ä¾‹å¥ï¼š` }
          ],
          temperature: 0.7,
          max_tokens: 100,
        });
        
        const generated = (response.choices?.[0]?.message?.content || '').trim();
        
        if (generated && generated.length > 5 && generated.length < 200) {
          const translation = await translate(generated, lang);
          sentences.push({
            original: generated,
            translation,
            context: name,
          });
        }
      } catch (e) {
        console.error('Generation failed:', e);
      }
    }

    return sentences.slice(0, 5);
  }, [isReady]);

  return { 
    isReady, 
    isLoading, 
    progress, 
    error, 
    currentModel,
    availableModels,
    loadModel,
    generateSentences 
  };
}

// ç¿»è­¯
async function translate(text: string, fromLang: string): Promise<string> {
  try {
    const from = fromLang === 'ja' ? 'ja' : fromLang === 'zh' ? 'zh' : 'en';
    const to = fromLang === 'en' ? 'zh' : 'en';
    
    const response = await fetch(
      `https://api.mymemory.translated.net/get?q=${encodeURIComponent(text)}&langpair=${from}|${to}`
    );
    const data = await response.json();
    return data.responseData?.translatedText || '(ç¿»è­¯å¤±æ•—)';
  } catch {
    return '(ç¿»è­¯å¤±æ•—)';
  }
}

// æ’­æ”¾éŸ³é »
export function playAudio(text: string, lang: string) {
  if (typeof window === 'undefined') return;
  if (!('speechSynthesis' in window)) return;

  window.speechSynthesis.cancel();
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = langConfigs[lang]?.voice || 'en-US';
  utterance.rate = 0.9;
  window.speechSynthesis.speak(utterance);
}

// æ­·å²è¨˜éŒ„
export function useHistory() {
  const [history, setHistory] = useState<Array<{ word: string; lang: string }>>([]);
  const [isClient, setIsClient] = useState(false);

  useEffect(() => {
    setIsClient(true);
    const saved = localStorage.getItem('lang-learn-history');
    if (saved) {
      setHistory(JSON.parse(saved));
    }
  }, []);

  const addToHistory = useCallback((word: string, lang: string) => {
    if (!isClient) return;
    setHistory((prev) => {
      const filtered = prev.filter((h) => !(h.word === word && h.lang === lang));
      const newHistory = [{ word, lang }, ...filtered].slice(0, 20);
      localStorage.setItem('lang-learn-history', JSON.stringify(newHistory));
      return newHistory;
    });
  }, [isClient]);

  const clearHistory = useCallback(() => {
    if (!isClient) return;
    setHistory([]);
    localStorage.removeItem('lang-learn-history');
  }, [isClient]);

  return { history, addToHistory, clearHistory, isClient };
}

// ä¸»é¡Œåˆ‡æ›
export function useTheme() {
  const [theme, setTheme] = useState<'light' | 'dark'>('dark');
  const [mounted, setMounted] = useState(false);

  useEffect(() => {
    setMounted(true);
    const saved = localStorage.getItem('lang-learn-theme') as 'light' | 'dark';
    if (saved) {
      setTheme(saved);
      document.documentElement.setAttribute('data-theme', saved);
    } else {
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      const initialTheme = prefersDark ? 'dark' : 'light';
      setTheme(initialTheme);
      document.documentElement.setAttribute('data-theme', initialTheme);
    }
  }, []);

  const toggleTheme = useCallback(() => {
    const newTheme = theme === 'light' ? 'dark' : 'light';
    setTheme(newTheme);
    document.documentElement.setAttribute('data-theme', newTheme);
    localStorage.setItem('lang-learn-theme', newTheme);
  }, [theme]);

  return { theme, toggleTheme, mounted };
}
