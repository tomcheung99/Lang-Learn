'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import * as webllm from '@mlc-ai/web-llm';

// é¡å‹å®šç¾©
export interface Sentence {
  original: string;
  translation: string;
  context: string;
}

export interface WordResult {
  word: string;
  meaning: string;
  sentences: Sentence[];
}

export interface LoadingProgress {
  text: string;
  progress: number;
}

export interface ModelConfig {
  id: string;
  name: string;
  description: string;
  size: string;
  modelId: string;
}

// æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨
// model_id å¿…é ˆç²¾ç¢ºåŒ¹é… webllm.prebuiltAppConfig.model_list ä¸­çš„ model_id
export const availableModels: ModelConfig[] = [
  {
    id: 'llama-3.2-1b',
    name: 'Llama 3.2 1B',
    description: 'Meta æœ€æ–°ï¼Œé€Ÿåº¦æœ€å¿«',
    size: '~400MB',
    modelId: 'Llama-3.2-1B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'llama-3.2-3b',
    name: 'Llama 3.2 3B',
    description: 'Meta æœ€æ–°ï¼Œè³ªé‡æ›´å¥½',
    size: '~1.2GB',
    modelId: 'Llama-3.2-3B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'qwen-2.5-1.5b',
    name: 'Qwen 2.5 1.5B',
    description: 'é˜¿é‡Œå·´å·´ï¼Œä¸­æ–‡æ¥µå¼·',
    size: '~800MB',
    modelId: 'Qwen2.5-1.5B-Instruct-q4f32_1-MLC',
  },
  {
    id: 'smollm-1.7b',
    name: 'SmolLM 1.7B',
    description: 'Hugging Faceï¼Œæœ€æ–°å°æ¨¡å‹',
    size: '~750MB',
    modelId: 'SmolLM2-1.7B-Instruct-q4f16_1-MLC',
  },
  {
    id: 'phi-3.5',
    name: 'Phi 3.5 Mini',
    description: 'Microsoftï¼Œæ¨ç†èƒ½åŠ›å¼·',
    size: '~900MB',
    modelId: 'Phi-3.5-mini-instruct-q4f16_1-MLC',
  },
  // 2025-2026 æœ€æ–°æ¨¡å‹
  {
    id: 'qwen3-0.6b',
    name: 'Qwen3 0.6B',
    description: 'é˜¿é‡Œæœ€æ–°è¶…è¼•é‡ï¼Œä¸­æ–‡æ¥µå¼·',
    size: '~900MB',
    modelId: 'Qwen3-0.6B-q4f16_1-MLC',
  },
  {
    id: 'qwen3-1.7b',
    name: 'Qwen3 1.7B',
    description: 'Qwen3 ç³»åˆ—ï¼Œæ€§èƒ½æ›´å¼·',
    size: '~1.3GB',
    modelId: 'Qwen3-1.7B-q4f16_1-MLC',
  },
  {
    id: 'qwen3-4b',
    name: 'Qwen3 4B',
    description: 'Qwen3 ä¸­å‹ç‰ˆæœ¬ï¼Œå¹³è¡¡ä¹‹é¸',
    size: '~2.2GB',
    modelId: 'Qwen3-4B-q4f16_1-MLC',
  },
  {
    id: 'ministral-3-3b-instruct',
    name: 'Ministral-3 3B Instruct',
    description: 'Mistral 2026 æœ€æ–° 3B ç³»åˆ—',
    size: '~2.0GB',
    modelId: 'Ministral-3-3B-Instruct-2512-BF16-q4f16_1-MLC',
  },
  {
    id: 'ministral-3-3b-reasoning',
    name: 'Ministral-3 3B Reasoning',
    description: 'Mistral æ¨ç†å°ˆç”¨ç‰ˆæœ¬ï¼ˆ2026æ–°ï¼‰',
    size: '~2.0GB',
    modelId: 'Ministral-3-3B-Reasoning-2512-q4f16_1-MLC',
  },
  {
    id: 'gemma-2-2b',
    name: 'Gemma-2 2B',
    description: 'Google æœ€æ–° Gemma 2 ç³»åˆ—',
    size: '~1.3GB',
    modelId: 'gemma-2-2b-it-q4f16_1-MLC',
  },
  {
    id: 'qwen2.5-coder-1.5b',
    name: 'Qwen2.5-Coder 1.5B',
    description: 'å°ˆæ¥­ç¨‹å¼ç¢¼ç”Ÿæˆæ¨¡å‹',
    size: '~1.0GB',
    modelId: 'Qwen2.5-Coder-1.5B-Instruct-q4f16_1-MLC',
  },
];

// èªè¨€é…ç½®
export const langConfigs: Record<string, { placeholder: string; icon: string; voice: string; name: string; systemPrompt: string }> = {
  ja: { 
    placeholder: 'è¼¸å…¥æ—¥æ–‡...', 
    icon: 'ğŸ‡¯ğŸ‡µ', 
    voice: 'ja-JP', 
    name: 'æ—¥æœ¬èª',
    systemPrompt: 'ä½ æ˜¯æ—¥èªæ•™å­¸åŠ©æ‰‹ã€‚è«‹ç”¨ç”¨æˆ¶æä¾›çš„å–®å­—ç”Ÿæˆè‡ªç„¶çš„æ—¥æ–‡ä¾‹å¥ï¼Œä¸¦æä¾›ä¸­æ–‡ç¿»è­¯ã€‚æ ¼å¼ï¼šæ—¥æ–‡ä¾‹å¥|ä¸­æ–‡ç¿»è­¯ã€‚åªè¼¸å‡ºé€™å€‹æ ¼å¼ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡‹ã€‚'
  },
  en: { 
    placeholder: 'Type English...', 
    icon: 'ğŸ‡¬ğŸ‡§', 
    voice: 'en-US', 
    name: 'English',
    systemPrompt: 'You are an English teaching assistant. Generate a natural English sentence using the provided word, and provide Chinese translation. Format: English sentence|ä¸­æ–‡ç¿»è­¯. Output only this format, no other explanation.'
  },
  zh: { 
    placeholder: 'è¼¸å…¥ä¸­æ–‡...', 
    icon: 'ğŸ‡¹ğŸ‡¼', 
    voice: 'zh-TW', 
    name: 'ä¸­æ–‡',
    systemPrompt: 'ä½ æ˜¯ä¸­æ–‡æ•™å­¸åŠ©æ‰‹ã€‚è«‹ç”¨ç”¨æˆ¶æä¾›çš„å–®å­—ç”Ÿæˆè‡ªç„¶çš„ä¸­æ–‡ä¾‹å¥ï¼Œä¸¦æä¾›è‹±æ–‡ç¿»è­¯ã€‚æ ¼å¼ï¼šä¸­æ–‡ä¾‹å¥|English translationã€‚åªè¼¸å‡ºé€™å€‹æ ¼å¼ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡‹ã€‚'
  },
};

// èªå¢ƒé…ç½®ï¼ˆå°å‡ºä¾› UI ä½¿ç”¨ï¼‰
export interface ContextConfig {
  id: string;
  name: string;
  desc: string;
  prompt: string;
  icon: string;
}

export const allContexts: ContextConfig[] = [
  { id: 'daily', name: 'æ—¥å¸¸å°è©±', desc: 'daily conversation', prompt: 'æ—¥å¸¸å°è©±çš„ä¾‹å¥', icon: 'ğŸ’¬' },
  { id: 'work', name: 'å·¥ä½œå ´æ™¯', desc: 'work situation', prompt: 'å·¥ä½œå ´æ™¯çš„ä¾‹å¥', icon: 'ğŸ’¼' },
  { id: 'emotion', name: 'æƒ…æ„Ÿè¡¨é”', desc: 'emotional expression', prompt: 'æƒ…æ„Ÿè¡¨é”çš„ä¾‹å¥', icon: 'â¤ï¸' },
  { id: 'describe', name: 'æè¿°äº‹ç‰©', desc: 'describing something', prompt: 'æè¿°äº‹ç‰©çš„ä¾‹å¥', icon: 'ğŸ”' },
  { id: 'help', name: 'è«‹æ±‚å¹«åŠ©', desc: 'asking for help', prompt: 'è«‹æ±‚å¹«åŠ©çš„ä¾‹å¥', icon: 'ğŸ™' },
  { id: 'travel', name: 'æ—…è¡Œå‡ºéŠ', desc: 'travel and tourism', prompt: 'æ—…è¡Œå‡ºéŠçš„ä¾‹å¥', icon: 'âœˆï¸' },
  { id: 'food', name: 'ç¾é£Ÿæ–™ç†', desc: 'food and cooking', prompt: 'ç¾é£Ÿæ–™ç†çš„ä¾‹å¥', icon: 'ğŸœ' },
  { id: 'literature', name: 'æ–‡å­¸æ›¸é¢', desc: 'literary expression', prompt: 'æ–‡å­¸æ›¸é¢èªçš„ä¾‹å¥', icon: 'ğŸ“š' },
  { id: 'casual', name: 'å£èªä¿šèª', desc: 'slang and casual', prompt: 'å£èªæˆ–ä¿šèªçš„ä¾‹å¥', icon: 'ğŸ˜' },
  { id: 'academic', name: 'å­¸è¡“æ­£å¼', desc: 'academic and formal', prompt: 'å­¸è¡“æˆ–æ­£å¼å ´åˆçš„ä¾‹å¥', icon: 'ğŸ“' },
];

// æ¸…é™¤ AI è¼¸å‡ºä¸­çš„ thinking æ¨™ç±¤ï¼ˆQwen3 ç­‰æ¨ç†æ¨¡å‹æœƒè¼¸å‡º <think>...</think>ï¼‰
function stripThinkingTags(text: string): string {
  // ç§»é™¤ <think>...</think> å€å¡Šï¼ˆåŒ…å«æ›è¡Œï¼‰
  let cleaned = text.replace(/<think>[\s\S]*?<\/think>/gi, '');
  // ç§»é™¤æœªé–‰åˆçš„ <think>... å€å¡Š
  cleaned = cleaned.replace(/<think>[\s\S]*/gi, '');
  // ç§»é™¤æ®˜ç•™çš„ </think>
  cleaned = cleaned.replace(/<\/think>/gi, '');
  cleaned = cleaned.trim();
  
  // å¦‚æœæ¸…ç†å¾Œæœ‰å¤šè¡Œï¼Œå˜—è©¦æ‰¾åˆ°åŒ…å« | çš„é‚£è¡Œ
  if (cleaned.includes('\n')) {
    const lines = cleaned.split('\n').map((l: string) => l.trim()).filter((l: string) => l.length > 0);
    const pipeLine = lines.find((l: string) => l.includes('|'));
    if (pipeLine) return pipeLine;
    // æ²’æœ‰ | å°±å–æœ€å¾Œä¸€è¡Œï¼ˆé€šå¸¸æ˜¯ç­”æ¡ˆï¼‰
    return lines[lines.length - 1] || cleaned;
  }
  
  return cleaned;
}

// WebLLM Hook
export function useWebLLM() {
  const [isReady, setIsReady] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isGenerating, setIsGenerating] = useState(false);
  const [progress, setProgress] = useState<LoadingProgress | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [currentModel, setCurrentModel] = useState<string>('llama-3.2-1b');
  const [loadingModelName, setLoadingModelName] = useState<string | null>(null);
  const chatRef = useRef<any>(null);
  const isClient = typeof window !== 'undefined';

  // åˆå§‹åŒ–æˆ–åˆ‡æ›æ¨¡å‹
  const loadModel = useCallback(async (modelId: string) => {
    if (!isClient) return;
    
    const modelConfig = availableModels.find(m => m.id === modelId);
    if (!modelConfig) return;

    try {
      setIsLoading(true);
      setError(null);
      setLoadingModelName(modelConfig.name);
      
      // å¦‚æœå·²æœ‰æ¨¡å‹ï¼Œå…ˆå¸è¼‰
      if (chatRef.current) {
        try {
          await chatRef.current.unload();
        } catch (e) {
          console.warn('Error unloading engine:', e);
        }
        chatRef.current = null;
      }
      
      const loadStartTime = performance.now();
      console.log(`[WebLLM] é–‹å§‹è¼‰å…¥æ¨¡å‹: ${modelConfig.name} (${modelConfig.modelId})`);
      
      // ä½¿ç”¨ CreateMLCEngine API
      const engine = await webllm.CreateMLCEngine(modelConfig.modelId, {
        initProgressCallback: (report: any) => {
          if (report) {
            setProgress({
              text: report.text || 'è¼‰å…¥ä¸­...',
              progress: typeof report.progress === 'number' ? report.progress : 0,
            });
          }
        },
      });
      
      const loadTime = ((performance.now() - loadStartTime) / 1000).toFixed(1);
      console.log(`[WebLLM] âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ: ${modelConfig.name}ï¼Œè€—æ™‚ ${loadTime}s`);
      
      chatRef.current = engine;
      setCurrentModel(modelId);
      setIsReady(true);
      setError(null);
    } catch (err: any) {
      console.error('WebLLM init failed:', err);
      // å¦‚æœæ˜¯æ¨¡å‹ä¸å­˜åœ¨éŒ¯èª¤ï¼Œå˜—è©¦ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„æ¨¡å‹
      if (err.message && err.message.includes('Cannot find model')) {
        setError('æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨ Llama 3.2 1B');
        // éè¿´èª¿ç”¨ï¼Œæ”¹ç”¨å‚™é¸æ¨¡å‹
        if (modelId !== 'llama-3.2-1b') {
          setTimeout(() => loadModel('llama-3.2-1b'), 1000);
        } else {
          setError('æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼šæ²’æœ‰å¯ç”¨çš„å‚™é¸æ¨¡å‹');
          setIsReady(false);
        }
      } else {
        setError(err.message || 'æ¨¡å‹è¼‰å…¥å¤±æ•—');
        setIsReady(false);
      }
    } finally {
      setIsLoading(false);
      setProgress(null);
      setLoadingModelName(null);
    }
  }, [isClient]);

  // åˆå§‹è¼‰å…¥é»˜èªæ¨¡å‹
  useEffect(() => {
    loadModel('llama-3.2-1b');
  }, [loadModel]);

  const generateSentences = useCallback(async (
    word: string,
    lang: string,
    selectedContextIds?: string[],
    onSentence?: (sentence: Sentence) => void
  ): Promise<Sentence[]> => {
    if (!chatRef.current || !isReady) return [];

    setIsGenerating(true);
    const totalStartTime = performance.now();
    console.log(`[WebLLM] ğŸ”„ é–‹å§‹ç”Ÿæˆä¾‹å¥: "${word}" (${lang})`);
    
    const sentences: Sentence[] = [];
    const config = langConfigs[lang];
    
    // æ ¹æ“šç”¨æˆ¶é¸æ“‡éæ¿¾èªå¢ƒ
    const selectedContexts = selectedContextIds && selectedContextIds.length > 0
      ? allContexts.filter(c => selectedContextIds.includes(c.id))
      : allContexts.slice(0, 5); // é»˜èªå‰5å€‹

    for (const { name, prompt } of selectedContexts) {
      try {
        const sentenceStartTime = performance.now();
        
        const response = await chatRef.current.chat.completions.create({
          messages: [
            { role: 'system', content: config.systemPrompt },
            { role: 'user', content: `å–®å­—ï¼š"${word}"\nèªå¢ƒï¼š${prompt}\n\nè«‹ç”Ÿæˆä¸€å€‹è‡ªç„¶çš„ä¾‹å¥ï¼š` }
          ],
          temperature: 0.7,
          max_tokens: 120,
        });
        
        const rawGenerated = (response.choices?.[0]?.message?.content || '').trim();
        // æ¸…é™¤ thinking æ¨™ç±¤ï¼ˆQwen3 ç­‰æ¨ç†æ¨¡å‹ï¼‰
        const generated = stripThinkingTags(rawGenerated);
        
        const sentenceTime = ((performance.now() - sentenceStartTime) / 1000).toFixed(1);
        console.log(`[WebLLM]   ğŸ“ [${name}] ${sentenceTime}s - åŸå§‹: "${rawGenerated.substring(0, 80)}..."`);
        if (rawGenerated !== generated) {
          console.log(`[WebLLM]   ğŸ§¹ å·²æ¸…é™¤ thinking æ¨™ç±¤, æ¸…ç†å¾Œ: "${generated.substring(0, 80)}..."`);
        }
        
        let sentence: Sentence | null = null;
        
        // è§£æ "åŸæ–‡|ç¿»è­¯" æ ¼å¼
        if (generated && generated.includes('|')) {
          const parts = generated.split('|');
          const original = parts[0].trim();
          const translation = parts.slice(1).join('|').trim(); // ç¿»è­¯éƒ¨åˆ†å¯èƒ½åŒ…å« |
          if (original && translation && original.length > 2 && original.length < 300) {
            sentence = { original, translation, context: name };
          }
        }
        
        // å‚™ç”¨æ–¹æ¡ˆï¼šå¦‚æœ LLM æ²’æœ‰æŒ‰æ ¼å¼è¼¸å‡ºï¼Œä»ä½¿ç”¨ç¿»è­¯ API
        if (!sentence && generated && generated.length > 3 && generated.length < 300) {
          console.log(`[WebLLM]   âš ï¸ æœªæŒ‰æ ¼å¼è¼¸å‡ºï¼Œä½¿ç”¨ç¿»è­¯ API`);
          const translation = await translate(generated, lang);
          sentence = { original: generated, translation, context: name };
        }
        
        if (sentence) {
          sentences.push(sentence);
          // é€æ¢å›èª¿é€šçŸ¥ UI
          if (onSentence) {
            onSentence(sentence);
          }
        }
      } catch (e) {
        console.error('[WebLLM]   âŒ Generation failed:', e);
      }
    }

    const totalTime = ((performance.now() - totalStartTime) / 1000).toFixed(1);
    console.log(`[WebLLM] âœ… ç”Ÿæˆå®Œæˆ: ${sentences.length} å€‹ä¾‹å¥ï¼Œç¸½è€—æ™‚ ${totalTime}s`);
    setIsGenerating(false);
    return sentences;
  }, [isReady]);

  return { 
    isReady, 
    isLoading, 
    isGenerating,
    progress, 
    error, 
    currentModel,
    loadingModelName,
    availableModels,
    loadModel,
    generateSentences 
  };
}

// ç¿»è­¯
async function translate(text: string, fromLang: string): Promise<string> {
  try {
    const from = fromLang === 'ja' ? 'ja' : fromLang === 'zh' ? 'zh' : 'en';
    const to = fromLang === 'en' ? 'zh' : 'en';
    
    const response = await fetch(
      `https://api.mymemory.translated.net/get?q=${encodeURIComponent(text)}&langpair=${from}|${to}`
    );
    const data = await response.json();
    return data.responseData?.translatedText || '(ç¿»è­¯å¤±æ•—)';
  } catch {
    return '(ç¿»è­¯å¤±æ•—)';
  }
}

// æ’­æ”¾éŸ³é »
export function playAudio(text: string, lang: string) {
  if (typeof window === 'undefined') return;
  if (!('speechSynthesis' in window)) return;

  window.speechSynthesis.cancel();
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = langConfigs[lang]?.voice || 'en-US';
  utterance.rate = 0.9;
  window.speechSynthesis.speak(utterance);
}

// æ­·å²è¨˜éŒ„
export function useHistory() {
  const [history, setHistory] = useState<Array<{ word: string; lang: string }>>([]);
  const [isClient, setIsClient] = useState(false);

  useEffect(() => {
    setIsClient(true);
    const saved = localStorage.getItem('lang-learn-history');
    if (saved) {
      setHistory(JSON.parse(saved));
    }
  }, []);

  const addToHistory = useCallback((word: string, lang: string) => {
    if (!isClient) return;
    setHistory((prev) => {
      const filtered = prev.filter((h) => !(h.word === word && h.lang === lang));
      const newHistory = [{ word, lang }, ...filtered].slice(0, 20);
      localStorage.setItem('lang-learn-history', JSON.stringify(newHistory));
      return newHistory;
    });
  }, [isClient]);

  const clearHistory = useCallback(() => {
    if (!isClient) return;
    setHistory([]);
    localStorage.removeItem('lang-learn-history');
  }, [isClient]);

  return { history, addToHistory, clearHistory, isClient };
}

// ä¸»é¡Œåˆ‡æ›
export function useTheme() {
  const [theme, setTheme] = useState<'light' | 'dark'>('dark');
  const [mounted, setMounted] = useState(false);

  useEffect(() => {
    setMounted(true);
    const saved = localStorage.getItem('lang-learn-theme') as 'light' | 'dark';
    if (saved) {
      setTheme(saved);
      document.documentElement.setAttribute('data-theme', saved);
    } else {
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      const initialTheme = prefersDark ? 'dark' : 'light';
      setTheme(initialTheme);
      document.documentElement.setAttribute('data-theme', initialTheme);
    }
  }, []);

  const toggleTheme = useCallback(() => {
    const newTheme = theme === 'light' ? 'dark' : 'light';
    setTheme(newTheme);
    document.documentElement.setAttribute('data-theme', newTheme);
    localStorage.setItem('lang-learn-theme', newTheme);
  }, [theme]);

  return { theme, toggleTheme, mounted };
}
